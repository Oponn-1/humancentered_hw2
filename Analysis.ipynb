{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data Into Pandas\n",
    "I use pandas to read the 'tab separated' data into a 'data frame' object for ease of interaction.\n",
    "\n",
    "Loading aggression annotation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>aggression</th>\n",
       "      <th>aggression_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>1362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37675</td>\n",
       "      <td>2408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37675</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37675</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37675</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365212</th>\n",
       "      <td>699897151</td>\n",
       "      <td>628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365213</th>\n",
       "      <td>699897151</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365214</th>\n",
       "      <td>699897151</td>\n",
       "      <td>57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365215</th>\n",
       "      <td>699897151</td>\n",
       "      <td>1815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365216</th>\n",
       "      <td>699897151</td>\n",
       "      <td>472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1365217 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rev_id  worker_id  aggression  aggression_score\n",
       "0            37675       1362         1.0              -1.0\n",
       "1            37675       2408         0.0               1.0\n",
       "2            37675       1493         0.0               0.0\n",
       "3            37675       1439         0.0               0.0\n",
       "4            37675        170         0.0               0.0\n",
       "...            ...        ...         ...               ...\n",
       "1365212  699897151        628         0.0               0.0\n",
       "1365213  699897151         15         0.0               0.0\n",
       "1365214  699897151         57         0.0               0.0\n",
       "1365215  699897151       1815         0.0               0.0\n",
       "1365216  699897151        472         0.0               0.0\n",
       "\n",
       "[1365217 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggression_labels = pd.DataFrame()\n",
    "aggression_labels = pd.read_csv('aggression_annotations.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading aggression comment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115859</th>\n",
       "      <td>699848324</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115860</th>\n",
       "      <td>699851288</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115861</th>\n",
       "      <td>699857133</td>\n",
       "      <td>NEWLINE_TOKEN:The way you're trying to describ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115862</th>\n",
       "      <td>699891012</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115863</th>\n",
       "      <td>699897151</td>\n",
       "      <td>Alternate option===NEWLINE_TOKENIs there perha...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115864 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rev_id                                            comment  year  \\\n",
       "0           37675  `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002   \n",
       "1           44816  `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002   \n",
       "2           49851  NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002   \n",
       "3           89320   Next, maybe you could work on being less cond...  2002   \n",
       "4           93890               This page will need disambiguation.   2002   \n",
       "...           ...                                                ...   ...   \n",
       "115859  699848324  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...  2016   \n",
       "115860  699851288  NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...  2016   \n",
       "115861  699857133  NEWLINE_TOKEN:The way you're trying to describ...  2016   \n",
       "115862  699891012  NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...  2016   \n",
       "115863  699897151  Alternate option===NEWLINE_TOKENIs there perha...  2016   \n",
       "\n",
       "        logged_in       ns   sample  split  \n",
       "0            True  article   random  train  \n",
       "1            True  article   random  train  \n",
       "2            True  article   random  train  \n",
       "3            True  article   random    dev  \n",
       "4            True  article   random  train  \n",
       "...           ...      ...      ...    ...  \n",
       "115859       True  article  blocked  train  \n",
       "115860       True  article  blocked   test  \n",
       "115861       True  article  blocked  train  \n",
       "115862       True     user  blocked    dev  \n",
       "115863       True  article  blocked  train  \n",
       "\n",
       "[115864 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggression_comments = pd.DataFrame()\n",
    "aggression_comments = pd.read_csv('aggression_annotated_comments.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading aggression worker data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>833</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1072</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>872</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>hs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2116</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>professional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>hs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>1442</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>hs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>529</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>hs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2036</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>masters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>393</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>masters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>3876</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2190 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      worker_id  gender  english_first_language age_group     education\n",
       "0           833  female                       0     45-60     bachelors\n",
       "1          1072    male                       0     30-45     bachelors\n",
       "2           872    male                       0     18-30            hs\n",
       "3          2116    male                       0     30-45  professional\n",
       "4           453    male                       0     30-45            hs\n",
       "...         ...     ...                     ...       ...           ...\n",
       "2185       1442    male                       0     18-30            hs\n",
       "2186        529  female                       0     30-45            hs\n",
       "2187       2036  female                       0     18-30       masters\n",
       "2188        393  female                       0     18-30       masters\n",
       "2189       3876  female                       1     30-45     bachelors\n",
       "\n",
       "[2190 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggression_workers = pd.DataFrame()\n",
    "aggression_workers = pd.read_csv('aggression_worker_demographics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading toxicity annotation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>toxicity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>3341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>1574</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598284</th>\n",
       "      <td>699897151.0</td>\n",
       "      <td>1550</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598285</th>\n",
       "      <td>699897151.0</td>\n",
       "      <td>1025</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598286</th>\n",
       "      <td>699897151.0</td>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598287</th>\n",
       "      <td>699897151.0</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598288</th>\n",
       "      <td>699897151.0</td>\n",
       "      <td>468</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598289 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              rev_id  worker_id  toxicity  toxicity_score\n",
       "0             2232.0        723         0             0.0\n",
       "1             2232.0       4000         0             0.0\n",
       "2             2232.0       3989         0             1.0\n",
       "3             2232.0       3341         0             0.0\n",
       "4             2232.0       1574         0             1.0\n",
       "...              ...        ...       ...             ...\n",
       "1598284  699897151.0       1550         0             0.0\n",
       "1598285  699897151.0       1025         0             1.0\n",
       "1598286  699897151.0        648         0             1.0\n",
       "1598287  699897151.0        379         0             0.0\n",
       "1598288  699897151.0        468         0             1.0\n",
       "\n",
       "[1598289 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_labels = pd.DataFrame()\n",
    "toxicity_labels = pd.read_csv('toxicity_annotations.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading toxicity comment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159681</th>\n",
       "      <td>699848324.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159682</th>\n",
       "      <td>699851288.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159683</th>\n",
       "      <td>699857133.0</td>\n",
       "      <td>NEWLINE_TOKEN:The way you're trying to describ...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159684</th>\n",
       "      <td>699891012.0</td>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>blocked</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159685</th>\n",
       "      <td>699897151.0</td>\n",
       "      <td>Alternate option===NEWLINE_TOKENIs there perha...</td>\n",
       "      <td>2016</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>blocked</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159686 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rev_id                                            comment  year  \\\n",
       "0            2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1            4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2            8953.0                          Elected or Electoral? JHK  2002   \n",
       "3           26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4           28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "...             ...                                                ...   ...   \n",
       "159681  699848324.0  `NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENThese ...  2016   \n",
       "159682  699851288.0  NEWLINE_TOKENNEWLINE_TOKENThe Institute for Hi...  2016   \n",
       "159683  699857133.0  NEWLINE_TOKEN:The way you're trying to describ...  2016   \n",
       "159684  699891012.0  NEWLINE_TOKENNEWLINE_TOKEN== Warning ==NEWLINE...  2016   \n",
       "159685  699897151.0  Alternate option===NEWLINE_TOKENIs there perha...  2016   \n",
       "\n",
       "        logged_in       ns   sample  split  \n",
       "0            True  article   random  train  \n",
       "1            True     user   random  train  \n",
       "2           False  article   random   test  \n",
       "3            True  article   random  train  \n",
       "4            True  article   random   test  \n",
       "...           ...      ...      ...    ...  \n",
       "159681       True  article  blocked  train  \n",
       "159682       True  article  blocked   test  \n",
       "159683       True  article  blocked    dev  \n",
       "159684       True     user  blocked  train  \n",
       "159685       True  article  blocked   test  \n",
       "\n",
       "[159686 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_comments = pd.DataFrame()\n",
    "toxicity_comments = pd.read_csv('toxicity_annotated_comments.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading toxicity worker data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>english_first_language</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1617</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1394</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>masters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>3189</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>1105</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>18-30</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588</th>\n",
       "      <td>2192</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>hs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>2692</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>30-45</td>\n",
       "      <td>hs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>4160</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>45-60</td>\n",
       "      <td>bachelors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3591 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      worker_id  gender  english_first_language age_group  education\n",
       "0            85  female                       0     18-30  bachelors\n",
       "1          1617  female                       0     45-60  bachelors\n",
       "2          1394  female                       0       NaN  bachelors\n",
       "3           311    male                       0     30-45  bachelors\n",
       "4          1980    male                       0     45-60    masters\n",
       "...         ...     ...                     ...       ...        ...\n",
       "3586       3189  female                       0     18-30  bachelors\n",
       "3587       1105  female                       0     18-30  bachelors\n",
       "3588       2192  female                       1  Under 18         hs\n",
       "3589       2692  female                       0     30-45         hs\n",
       "3590       4160    male                       0     45-60  bachelors\n",
       "\n",
       "[3591 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_workers = pd.DataFrame()\n",
    "toxicity_workers = pd.read_csv('toxicity_worker_demographics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "For both data sets loaded above, I investigate the question of whether different demographics find different words toxic or aggressive. This would provide some insight into just how much perception of the same content can differ, and therefore what kinds of words (if any) bring some bias into the labelling. If there are particular words for which the labels differ significantly by some demographic breakdown, then any model trained on the data would probably perform poorly when dealing with such words.\n",
    "\n",
    "First, I must select the annotations that indicate toxicity or aggression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_labels_bad = toxicity_labels.loc[toxicity_labels['toxicity'] == 1]\n",
    "\n",
    "aggression_labels_bad = aggression_labels.loc[aggression_labels['aggression'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I isolate the demographic data I will be focusing on: gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_worker_gender = toxicity_workers[['worker_id', 'gender']]\n",
    "\n",
    "agg_worker_gender = aggression_workers[['worker_id', 'gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I combine the gender data with the annotation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_labels_gender = toxicity_labels_bad.merge(tox_worker_gender, on='worker_id')\n",
    "\n",
    "agg_labels_gender = aggression_labels_bad.merge(agg_worker_gender, on='worker_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also isolate the comment data and combine it with the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_comments = toxicity_comments[['rev_id', 'comment']]\n",
    "\n",
    "agg_comments = aggression_comments[['rev_id', 'comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox = tox_labels_gender.merge(tox_comments, on='rev_id', how='inner')\n",
    "\n",
    "agg = agg_labels_gender.merge(agg_comments, on='rev_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I create an overall list of words for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This:NEWLINE_TOKEN:One',\n",
       " 'can',\n",
       " 'make',\n",
       " 'an',\n",
       " 'analogy',\n",
       " 'in',\n",
       " 'mathematical',\n",
       " 'terms',\n",
       " 'by',\n",
       " 'envisioning',\n",
       " 'the',\n",
       " 'distribution',\n",
       " 'of',\n",
       " 'opinions',\n",
       " 'in',\n",
       " 'a',\n",
       " 'population',\n",
       " 'as',\n",
       " 'a',\n",
       " 'Gaussian',\n",
       " 'curve.',\n",
       " 'We',\n",
       " 'would',\n",
       " 'then',\n",
       " 'say',\n",
       " 'that',\n",
       " 'the',\n",
       " 'consensus',\n",
       " 'would',\n",
       " 'be',\n",
       " 'a',\n",
       " 'statement',\n",
       " 'that',\n",
       " 'represents',\n",
       " 'the',\n",
       " 'range',\n",
       " 'of',\n",
       " 'opinions',\n",
       " 'within',\n",
       " 'perhaps',\n",
       " 'three',\n",
       " 'standard',\n",
       " 'deviations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'opinion.',\n",
       " 'NEWLINE_TOKENsounds',\n",
       " 'arbitrary',\n",
       " 'and',\n",
       " 'ad',\n",
       " 'hoc.',\n",
       " 'Does',\n",
       " 'it',\n",
       " 'really',\n",
       " 'belong',\n",
       " 'in',\n",
       " 'n',\n",
       " 'encyclopedia',\n",
       " 'article?',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'see',\n",
       " 'that',\n",
       " 'it',\n",
       " 'adds',\n",
       " 'anything',\n",
       " 'useful.NEWLINE_TOKENNEWLINE_TOKENThe',\n",
       " 'paragraph',\n",
       " 'that',\n",
       " 'follows',\n",
       " 'seems',\n",
       " 'much',\n",
       " 'more',\n",
       " 'useful.',\n",
       " 'Are',\n",
       " 'there',\n",
       " 'any',\n",
       " 'political',\n",
       " 'theorists',\n",
       " 'out',\n",
       " 'there',\n",
       " 'who',\n",
       " 'can',\n",
       " 'clarify',\n",
       " 'the',\n",
       " 'issues?',\n",
       " 'It',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'me',\n",
       " 'that',\n",
       " 'this',\n",
       " 'is',\n",
       " 'an',\n",
       " 'issue',\n",
       " 'that',\n",
       " 'Locke,',\n",
       " 'Rousseau,',\n",
       " 'de',\n",
       " 'Toqueville,',\n",
       " 'and',\n",
       " 'others',\n",
       " 'must',\n",
       " 'have',\n",
       " 'debated...',\n",
       " 'SRNEWLINE_TOKEN',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'Editing',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENPlease',\n",
       " 'refrain',\n",
       " 'from',\n",
       " 'adding',\n",
       " 'confusing',\n",
       " 'and',\n",
       " 'often',\n",
       " 'incorrect',\n",
       " 'information',\n",
       " 'to',\n",
       " 'articles.',\n",
       " 'Several',\n",
       " 'times',\n",
       " 'you',\n",
       " 'have',\n",
       " 'added',\n",
       " 'factually',\n",
       " 'incorrect',\n",
       " 'information',\n",
       " 'to',\n",
       " 'articles;',\n",
       " 'it',\n",
       " 'has',\n",
       " 'been',\n",
       " 'reverted;',\n",
       " 'and',\n",
       " 'you',\n",
       " 'have',\n",
       " 'continued',\n",
       " 'to',\n",
       " 're-add',\n",
       " 'them.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'do',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'I',\n",
       " 'will',\n",
       " 'have',\n",
       " 'to',\n",
       " 'report',\n",
       " 'you',\n",
       " 'for',\n",
       " 'vandalism,',\n",
       " 'which',\n",
       " 'could',\n",
       " 'lead',\n",
       " 'to',\n",
       " 'an',\n",
       " 'extended',\n",
       " 'block',\n",
       " 'on',\n",
       " 'your',\n",
       " 'contributions.',\n",
       " 'The',\n",
       " 'contested',\n",
       " 'items',\n",
       " 'are:NEWLINE_TOKEN#',\n",
       " 'Yakko,',\n",
       " 'Wakko,',\n",
       " 'and',\n",
       " 'Dot',\n",
       " '-',\n",
       " 'Please',\n",
       " 'stop',\n",
       " 'de-alphabetizing',\n",
       " 'the',\n",
       " 'list',\n",
       " 'of',\n",
       " 'sketches,',\n",
       " 'duplicating',\n",
       " 'information,',\n",
       " 'and',\n",
       " 'adding',\n",
       " 'unfounded',\n",
       " 'information',\n",
       " 'claiming',\n",
       " 'that',\n",
       " 'Scratchensniff',\n",
       " 'is',\n",
       " 'their',\n",
       " 'dad.NEWLINE_TOKEN#',\n",
       " 'Richie',\n",
       " 'Rich',\n",
       " '-',\n",
       " 'Please',\n",
       " 'stop',\n",
       " 'removing',\n",
       " 'information,',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " \"parents'\",\n",
       " 'first',\n",
       " 'namesNEWLINE_TOKEN#',\n",
       " 'Tiny',\n",
       " 'Toons',\n",
       " '-',\n",
       " 'Please',\n",
       " 'stop',\n",
       " 'claiming',\n",
       " 'that',\n",
       " 'Buster',\n",
       " 'and',\n",
       " 'Babs',\n",
       " 'are',\n",
       " 'siblingsNEWLINE_TOKENIf',\n",
       " 'you',\n",
       " 'dispute',\n",
       " 'any',\n",
       " 'of',\n",
       " 'this',\n",
       " 'information,',\n",
       " 'please',\n",
       " 'take',\n",
       " 'it',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'of',\n",
       " 'the',\n",
       " 'article.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'future,',\n",
       " 'if',\n",
       " 'someone',\n",
       " 'reverts',\n",
       " 'an',\n",
       " 'edit,',\n",
       " 'please',\n",
       " 'attempt',\n",
       " 'to',\n",
       " 'discuss',\n",
       " 'it',\n",
       " 'either',\n",
       " 'on',\n",
       " 'the',\n",
       " 'other',\n",
       " \"user's\",\n",
       " 'talk',\n",
       " 'page,',\n",
       " 'your',\n",
       " 'talk',\n",
       " 'page,',\n",
       " 'or',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'of',\n",
       " 'the',\n",
       " 'relevant',\n",
       " 'articles.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'add',\n",
       " 'this',\n",
       " 'disputed',\n",
       " 'information',\n",
       " 'without',\n",
       " 'discussion,',\n",
       " 'your',\n",
       " 'edits',\n",
       " 'will',\n",
       " 'be',\n",
       " 'summarily',\n",
       " 'reverted',\n",
       " 'as',\n",
       " 'vandalism.',\n",
       " '-',\n",
       " '`NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'postmodernism',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENre:',\n",
       " 'this:NEWLINE_TOKEN:',\n",
       " '``postmodern',\n",
       " 'thought,',\n",
       " 'which',\n",
       " 'regards',\n",
       " 'all',\n",
       " 'cultures',\n",
       " 'as',\n",
       " 'equally',\n",
       " 'worthy``NEWLINE_TOKENNEWLINE_TOKENIm',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'thats',\n",
       " 'an',\n",
       " 'accurate',\n",
       " 'portrayal',\n",
       " 'of',\n",
       " 'postmodern',\n",
       " 'thought?',\n",
       " 'I',\n",
       " 'may',\n",
       " 'be',\n",
       " 'wrong.',\n",
       " 'It',\n",
       " 'implies',\n",
       " 'political',\n",
       " 'correctness,',\n",
       " 'that',\n",
       " 'worthiness',\n",
       " 'is',\n",
       " 'contrived',\n",
       " 'for',\n",
       " 'an',\n",
       " 'idealistic',\n",
       " 'purpose,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'a',\n",
       " 'pejorative',\n",
       " 'concept.',\n",
       " '`',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'vandalise',\n",
       " 'it',\n",
       " 'you',\n",
       " 'cockface!',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENI',\n",
       " 'just',\n",
       " 'told',\n",
       " 'you',\n",
       " 'shut',\n",
       " 'up',\n",
       " 'and',\n",
       " 'sit',\n",
       " 'down.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'vandalise',\n",
       " 'it',\n",
       " 'you',\n",
       " 'cockface!',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENI',\n",
       " 'just',\n",
       " 'told',\n",
       " 'you',\n",
       " 'shut',\n",
       " 'up',\n",
       " 'and',\n",
       " 'sit',\n",
       " 'down.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'vandalise',\n",
       " 'it',\n",
       " 'you',\n",
       " 'cockface!',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENI',\n",
       " 'just',\n",
       " 'told',\n",
       " 'you',\n",
       " 'shut',\n",
       " 'up',\n",
       " 'and',\n",
       " 'sit',\n",
       " 'down.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'vandalise',\n",
       " 'it',\n",
       " 'you',\n",
       " 'cockface!',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENI',\n",
       " 'just',\n",
       " 'told',\n",
       " 'you',\n",
       " 'shut',\n",
       " 'up',\n",
       " 'and',\n",
       " 'sit',\n",
       " 'down.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'vandalise',\n",
       " 'it',\n",
       " 'you',\n",
       " 'cockface!',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENI',\n",
       " 'just',\n",
       " 'told',\n",
       " 'you',\n",
       " 'shut',\n",
       " 'up',\n",
       " 'and',\n",
       " 'sit',\n",
       " 'down.',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " '`',\n",
       " '(and',\n",
       " 'lest',\n",
       " 'we',\n",
       " 'forget,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'same',\n",
       " 'publication',\n",
       " 'that',\n",
       " 'ran',\n",
       " 'with',\n",
       " 'the',\n",
       " 'outrageously',\n",
       " 'false',\n",
       " '``story``',\n",
       " 'that',\n",
       " 'Governor',\n",
       " 'Rick',\n",
       " 'Perry',\n",
       " 'was',\n",
       " 'gay)`',\n",
       " 'Islamophobia',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKEN:That',\n",
       " 'may',\n",
       " 'be',\n",
       " 'so,',\n",
       " 'but',\n",
       " 'the',\n",
       " 'to',\n",
       " 'exclude',\n",
       " 'another',\n",
       " \"party's\",\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " 'even',\n",
       " 'if',\n",
       " 'that',\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'abhorrent',\n",
       " 'is',\n",
       " 'against',\n",
       " 'the',\n",
       " 'NPOV',\n",
       " 'policy,',\n",
       " 'which,',\n",
       " 'frankly,',\n",
       " 'reduces',\n",
       " 'the',\n",
       " \"article's\",\n",
       " 'utility',\n",
       " 'and',\n",
       " '(in',\n",
       " 'my',\n",
       " 'opinion)',\n",
       " 'makes',\n",
       " 'the',\n",
       " 'POV',\n",
       " 'party',\n",
       " 'look',\n",
       " 'bad.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'Islamophobia',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKEN:That',\n",
       " 'may',\n",
       " 'be',\n",
       " 'so,',\n",
       " 'but',\n",
       " 'the',\n",
       " 'to',\n",
       " 'exclude',\n",
       " 'another',\n",
       " \"party's\",\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " 'even',\n",
       " 'if',\n",
       " 'that',\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'abhorrent',\n",
       " 'is',\n",
       " 'against',\n",
       " 'the',\n",
       " 'NPOV',\n",
       " 'policy,',\n",
       " 'which,',\n",
       " 'frankly,',\n",
       " 'reduces',\n",
       " 'the',\n",
       " \"article's\",\n",
       " 'utility',\n",
       " 'and',\n",
       " '(in',\n",
       " 'my',\n",
       " 'opinion)',\n",
       " 'makes',\n",
       " 'the',\n",
       " 'POV',\n",
       " 'party',\n",
       " 'look',\n",
       " 'bad.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'Thanks',\n",
       " 'for',\n",
       " 'stepping',\n",
       " 'in',\n",
       " 'on',\n",
       " 'the',\n",
       " 'vandalism',\n",
       " 'on',\n",
       " 'Britches',\n",
       " '(monkey)==NEWLINE_TOKENthat',\n",
       " 'is',\n",
       " 'all.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'Thanks',\n",
       " 'for',\n",
       " 'stepping',\n",
       " 'in',\n",
       " 'on',\n",
       " 'the',\n",
       " 'vandalism',\n",
       " 'on',\n",
       " 'Britches',\n",
       " '(monkey)==NEWLINE_TOKENthat',\n",
       " 'is',\n",
       " 'all.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'Thanks',\n",
       " 'for',\n",
       " 'stepping',\n",
       " 'in',\n",
       " 'on',\n",
       " 'the',\n",
       " 'vandalism',\n",
       " 'on',\n",
       " 'Britches',\n",
       " '(monkey)==NEWLINE_TOKENthat',\n",
       " 'is',\n",
       " 'all.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'Thanks',\n",
       " 'for',\n",
       " 'stepping',\n",
       " 'in',\n",
       " 'on',\n",
       " 'the',\n",
       " 'vandalism',\n",
       " 'on',\n",
       " 'Britches',\n",
       " '(monkey)==NEWLINE_TOKENthat',\n",
       " 'is',\n",
       " 'all.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN:::Hey',\n",
       " 'Sophia,',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'your',\n",
       " 'comments.',\n",
       " 'My',\n",
       " 'concern',\n",
       " 'about',\n",
       " 'the',\n",
       " 'block',\n",
       " 'is',\n",
       " 'the',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'being',\n",
       " 'tarred',\n",
       " 'a',\n",
       " \"'problem\",\n",
       " \"user'\",\n",
       " 'over',\n",
       " 'time',\n",
       " 'due',\n",
       " 'to',\n",
       " 'a',\n",
       " 'rather',\n",
       " 'strict',\n",
       " 'and',\n",
       " 'selective',\n",
       " 'application',\n",
       " 'of',\n",
       " 'policy.',\n",
       " 'I',\n",
       " \"won't\",\n",
       " 'fight',\n",
       " 'this',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'technically',\n",
       " 'a',\n",
       " 'legal',\n",
       " 'block.',\n",
       " 'Still,',\n",
       " 'considering',\n",
       " 'that',\n",
       " 'AJA',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'discuss',\n",
       " 'on',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'while',\n",
       " 'reverting',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'peoples',\n",
       " 'work,',\n",
       " 'I',\n",
       " 'do',\n",
       " 'think',\n",
       " 'blocking',\n",
       " 'me',\n",
       " 'in',\n",
       " 'this',\n",
       " 'instance',\n",
       " 'is',\n",
       " 'questionable.',\n",
       " 'OTOH,',\n",
       " 'the',\n",
       " 'Acharya',\n",
       " 'S',\n",
       " 'edit',\n",
       " 'war',\n",
       " 'has',\n",
       " 'been',\n",
       " 'going',\n",
       " 'on',\n",
       " 'for',\n",
       " 'many',\n",
       " 'months,',\n",
       " 'and',\n",
       " 'Charles',\n",
       " 'has',\n",
       " 'applied',\n",
       " 'the',\n",
       " '3RR',\n",
       " 'strictly',\n",
       " 'against',\n",
       " 'others',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past,',\n",
       " 'so',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'feel',\n",
       " 'so',\n",
       " 'bad.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENbatista',\n",
       " 'is',\n",
       " 'also',\n",
       " '300',\n",
       " 'lbs',\n",
       " 'not',\n",
       " '317',\n",
       " 'thats',\n",
       " 'bullshit.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENbatista',\n",
       " 'is',\n",
       " 'also',\n",
       " '300',\n",
       " 'lbs',\n",
       " 'not',\n",
       " '317',\n",
       " 'thats',\n",
       " 'bullshit.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENbatista',\n",
       " 'is',\n",
       " 'also',\n",
       " '300',\n",
       " 'lbs',\n",
       " 'not',\n",
       " '317',\n",
       " 'thats',\n",
       " 'bullshit.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENbatista',\n",
       " 'is',\n",
       " 'also',\n",
       " '300',\n",
       " 'lbs',\n",
       " 'not',\n",
       " '317',\n",
       " 'thats',\n",
       " 'bullshit.',\n",
       " '`Cleanup',\n",
       " 'tag',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENIn',\n",
       " 'what',\n",
       " 'way',\n",
       " 'does',\n",
       " 'the',\n",
       " 'article',\n",
       " 'need',\n",
       " 'to',\n",
       " 'be',\n",
       " 'cleaned',\n",
       " 'up?',\n",
       " '[|email]',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " '`',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'IS',\n",
       " 'TAIWAN',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'COUNTRY',\n",
       " ',CHINA',\n",
       " 'PIGS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'PIG',\n",
       " '.',\n",
       " 'UNDERSTAND',\n",
       " 'ING?==',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'IS',\n",
       " 'TAIWAN',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'COUNTRY',\n",
       " ',CHINA',\n",
       " 'PIGS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'PIG',\n",
       " '.',\n",
       " 'UNDERSTAND',\n",
       " 'ING?==',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'IS',\n",
       " 'TAIWAN',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'COUNTRY',\n",
       " ',CHINA',\n",
       " 'PIGS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'PIG',\n",
       " '.',\n",
       " 'UNDERSTAND',\n",
       " 'ING?==',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'IS',\n",
       " 'TAIWAN',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'COUNTRY',\n",
       " ',CHINA',\n",
       " 'PIGS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'PIG',\n",
       " '.',\n",
       " 'UNDERSTAND',\n",
       " 'ING?==',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'IS',\n",
       " 'TAIWAN',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'COUNTRY',\n",
       " ',CHINA',\n",
       " 'PIGS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'PIG',\n",
       " '.',\n",
       " 'UNDERSTAND',\n",
       " 'ING?==',\n",
       " 'Bullshit=NEWLINE_TOKENThere',\n",
       " 'was',\n",
       " 'no',\n",
       " 'violation,',\n",
       " 'you',\n",
       " 'removed',\n",
       " 'factual',\n",
       " 'material.NEWLINE_TOKENNEWLINE_TOKEN:Ditto',\n",
       " 'again',\n",
       " 'the',\n",
       " 'above',\n",
       " 'statement.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'also',\n",
       " 'informed',\n",
       " \"Wikipedia's\",\n",
       " 'administrators',\n",
       " 'of',\n",
       " 'your',\n",
       " 'persistent',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'insert',\n",
       " 'subjective',\n",
       " 'material',\n",
       " 'into',\n",
       " 'this',\n",
       " 'article,',\n",
       " 'in',\n",
       " 'violation',\n",
       " 'of',\n",
       " 'WP:NPOV.',\n",
       " 'NEWLINE_TOKEN=Ditto',\n",
       " 'to',\n",
       " 'that=NEWLINE_TOKENThere',\n",
       " 'was',\n",
       " 'no',\n",
       " 'violation,',\n",
       " 'you',\n",
       " 'removed',\n",
       " 'factual',\n",
       " 'material.NEWLINE_TOKENNEWLINE_TOKEN::Greetings.',\n",
       " 'Uncyclopedia',\n",
       " 'is',\n",
       " 'not',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'Wikimedia,',\n",
       " 'and',\n",
       " 'continuing',\n",
       " 'to',\n",
       " 'insert',\n",
       " 'this',\n",
       " 'false',\n",
       " 'information',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'vandalism.',\n",
       " 'Also,',\n",
       " 'please',\n",
       " 'heed',\n",
       " \"Codeine's\",\n",
       " 'warnings',\n",
       " 'about',\n",
       " 'NPOV;',\n",
       " 'opinions',\n",
       " 'do',\n",
       " 'not',\n",
       " 'belong',\n",
       " 'in',\n",
       " 'Wikipedia',\n",
       " 'articles.',\n",
       " 'Thanks,',\n",
       " 'NEWLINE_TOKEN=Bullshit=NEWLINE_TOKENThere',\n",
       " 'is',\n",
       " 'a',\n",
       " 'connection',\n",
       " 'between',\n",
       " 'Wikia',\n",
       " 'and',\n",
       " 'Wikimedia,',\n",
       " 'Wikia',\n",
       " 'pwns',\n",
       " 'Uncyc.',\n",
       " 'Sorry,',\n",
       " 'loyalist.NEWLINE_TOKENNEWLINE_TOKEN==Your',\n",
       " 'edit',\n",
       " 'to',\n",
       " 'Uncyclopedia==NEWLINE_TOKENYour',\n",
       " 'recent',\n",
       " 'edit',\n",
       " 'to',\n",
       " 'Uncyclopedia',\n",
       " '(diff)',\n",
       " 'was',\n",
       " 'reverted',\n",
       " 'by',\n",
       " 'an',\n",
       " 'automated',\n",
       " 'bot',\n",
       " 'that',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'and',\n",
       " 'repair',\n",
       " 'vandalism',\n",
       " 'to',\n",
       " 'Wikipedia',\n",
       " 'articles.',\n",
       " 'If',\n",
       " 'the',\n",
       " 'bot',\n",
       " 'reverted',\n",
       " 'a',\n",
       " 'legitimate',\n",
       " 'edit,',\n",
       " 'please',\n",
       " 'accept',\n",
       " 'my',\n",
       " 'humble',\n",
       " \"creator's\",\n",
       " 'apologies',\n",
       " '–',\n",
       " 'if',\n",
       " 'you',\n",
       " 'bring',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'attention',\n",
       " 'of',\n",
       " 'the',\n",
       " \"bot's\",\n",
       " 'owner,',\n",
       " 'we',\n",
       " 'may',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'its',\n",
       " 'behavior.',\n",
       " \"'''\",\n",
       " 'for',\n",
       " 'frequently',\n",
       " 'asked',\n",
       " \"questions'''\",\n",
       " 'about',\n",
       " 'the',\n",
       " 'bot',\n",
       " 'and',\n",
       " 'this',\n",
       " 'warning.',\n",
       " '//',\n",
       " 'NEWLINE_TOKEN=',\n",
       " 'Bullshit=NEWLINE_TOKENThere',\n",
       " 'was',\n",
       " 'no',\n",
       " 'violation,',\n",
       " 'you',\n",
       " 'removed',\n",
       " 'factual',\n",
       " 'material.NEWLINE_TOKENNEWLINE_TOKEN:Ditto',\n",
       " 'again',\n",
       " 'the',\n",
       " 'above',\n",
       " 'statement.',\n",
       " 'I',\n",
       " 'have',\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_tox_words = []\n",
    "male_tox = tox.loc[tox['gender'] == 'male']\n",
    "male_tox.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(male_tox)):\n",
    "    male_tox_words.extend(male_tox['comment'][i].split())\n",
    "    \n",
    "male_tox_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'I',\n",
       " \"didn't\",\n",
       " 'vandalise',\n",
       " 'it',\n",
       " 'you',\n",
       " 'cockface!',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENI',\n",
       " 'just',\n",
       " 'told',\n",
       " 'you',\n",
       " 'shut',\n",
       " 'up',\n",
       " 'and',\n",
       " 'sit',\n",
       " 'down.',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " \"NEWLINE_TOKENNEWLINE_TOKENI'LL\",\n",
       " 'KILL',\n",
       " 'YOU',\n",
       " 'ALL!!!!',\n",
       " '`',\n",
       " '(and',\n",
       " 'lest',\n",
       " 'we',\n",
       " 'forget,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'same',\n",
       " 'publication',\n",
       " 'that',\n",
       " 'ran',\n",
       " 'with',\n",
       " 'the',\n",
       " 'outrageously',\n",
       " 'false',\n",
       " '``story``',\n",
       " 'that',\n",
       " 'Governor',\n",
       " 'Rick',\n",
       " 'Perry',\n",
       " 'was',\n",
       " 'gay)`',\n",
       " 'Islamophobia',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKEN:That',\n",
       " 'may',\n",
       " 'be',\n",
       " 'so,',\n",
       " 'but',\n",
       " 'the',\n",
       " 'to',\n",
       " 'exclude',\n",
       " 'another',\n",
       " \"party's\",\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " 'even',\n",
       " 'if',\n",
       " 'that',\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " 'is',\n",
       " 'seen',\n",
       " 'as',\n",
       " 'abhorrent',\n",
       " 'is',\n",
       " 'against',\n",
       " 'the',\n",
       " 'NPOV',\n",
       " 'policy,',\n",
       " 'which,',\n",
       " 'frankly,',\n",
       " 'reduces',\n",
       " 'the',\n",
       " \"article's\",\n",
       " 'utility',\n",
       " 'and',\n",
       " '(in',\n",
       " 'my',\n",
       " 'opinion)',\n",
       " 'makes',\n",
       " 'the',\n",
       " 'POV',\n",
       " 'party',\n",
       " 'look',\n",
       " 'bad.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN:::Hey',\n",
       " 'Sophia,',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'your',\n",
       " 'comments.',\n",
       " 'My',\n",
       " 'concern',\n",
       " 'about',\n",
       " 'the',\n",
       " 'block',\n",
       " 'is',\n",
       " 'the',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'being',\n",
       " 'tarred',\n",
       " 'a',\n",
       " \"'problem\",\n",
       " \"user'\",\n",
       " 'over',\n",
       " 'time',\n",
       " 'due',\n",
       " 'to',\n",
       " 'a',\n",
       " 'rather',\n",
       " 'strict',\n",
       " 'and',\n",
       " 'selective',\n",
       " 'application',\n",
       " 'of',\n",
       " 'policy.',\n",
       " 'I',\n",
       " \"won't\",\n",
       " 'fight',\n",
       " 'this',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'technically',\n",
       " 'a',\n",
       " 'legal',\n",
       " 'block.',\n",
       " 'Still,',\n",
       " 'considering',\n",
       " 'that',\n",
       " 'AJA',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'discuss',\n",
       " 'on',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'while',\n",
       " 'reverting',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'peoples',\n",
       " 'work,',\n",
       " 'I',\n",
       " 'do',\n",
       " 'think',\n",
       " 'blocking',\n",
       " 'me',\n",
       " 'in',\n",
       " 'this',\n",
       " 'instance',\n",
       " 'is',\n",
       " 'questionable.',\n",
       " 'OTOH,',\n",
       " 'the',\n",
       " 'Acharya',\n",
       " 'S',\n",
       " 'edit',\n",
       " 'war',\n",
       " 'has',\n",
       " 'been',\n",
       " 'going',\n",
       " 'on',\n",
       " 'for',\n",
       " 'many',\n",
       " 'months,',\n",
       " 'and',\n",
       " 'Charles',\n",
       " 'has',\n",
       " 'applied',\n",
       " 'the',\n",
       " '3RR',\n",
       " 'strictly',\n",
       " 'against',\n",
       " 'others',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past,',\n",
       " 'so',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'feel',\n",
       " 'so',\n",
       " 'bad.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN:::Hey',\n",
       " 'Sophia,',\n",
       " 'thanks',\n",
       " 'for',\n",
       " 'your',\n",
       " 'comments.',\n",
       " 'My',\n",
       " 'concern',\n",
       " 'about',\n",
       " 'the',\n",
       " 'block',\n",
       " 'is',\n",
       " 'the',\n",
       " 'risk',\n",
       " 'of',\n",
       " 'being',\n",
       " 'tarred',\n",
       " 'a',\n",
       " \"'problem\",\n",
       " \"user'\",\n",
       " 'over',\n",
       " 'time',\n",
       " 'due',\n",
       " 'to',\n",
       " 'a',\n",
       " 'rather',\n",
       " 'strict',\n",
       " 'and',\n",
       " 'selective',\n",
       " 'application',\n",
       " 'of',\n",
       " 'policy.',\n",
       " 'I',\n",
       " \"won't\",\n",
       " 'fight',\n",
       " 'this',\n",
       " 'because',\n",
       " 'it',\n",
       " 'is',\n",
       " 'technically',\n",
       " 'a',\n",
       " 'legal',\n",
       " 'block.',\n",
       " 'Still,',\n",
       " 'considering',\n",
       " 'that',\n",
       " 'AJA',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'discuss',\n",
       " 'on',\n",
       " 'the',\n",
       " 'talk',\n",
       " 'page',\n",
       " 'while',\n",
       " 'reverting',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'peoples',\n",
       " 'work,',\n",
       " 'I',\n",
       " 'do',\n",
       " 'think',\n",
       " 'blocking',\n",
       " 'me',\n",
       " 'in',\n",
       " 'this',\n",
       " 'instance',\n",
       " 'is',\n",
       " 'questionable.',\n",
       " 'OTOH,',\n",
       " 'the',\n",
       " 'Acharya',\n",
       " 'S',\n",
       " 'edit',\n",
       " 'war',\n",
       " 'has',\n",
       " 'been',\n",
       " 'going',\n",
       " 'on',\n",
       " 'for',\n",
       " 'many',\n",
       " 'months,',\n",
       " 'and',\n",
       " 'Charles',\n",
       " 'has',\n",
       " 'applied',\n",
       " 'the',\n",
       " '3RR',\n",
       " 'strictly',\n",
       " 'against',\n",
       " 'others',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past,',\n",
       " 'so',\n",
       " 'I',\n",
       " \"don't\",\n",
       " 'feel',\n",
       " 'so',\n",
       " 'bad.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENbatista',\n",
       " 'is',\n",
       " 'also',\n",
       " '300',\n",
       " 'lbs',\n",
       " 'not',\n",
       " '317',\n",
       " 'thats',\n",
       " 'bullshit.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENbatista',\n",
       " 'is',\n",
       " 'also',\n",
       " '300',\n",
       " 'lbs',\n",
       " 'not',\n",
       " '317',\n",
       " 'thats',\n",
       " 'bullshit.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'IS',\n",
       " 'TAIWAN',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'COUNTRY',\n",
       " ',CHINA',\n",
       " 'PIGS',\n",
       " 'IS',\n",
       " 'JUST',\n",
       " 'PIG',\n",
       " '.',\n",
       " 'UNDERSTAND',\n",
       " 'ING?==',\n",
       " 'Bullshit=NEWLINE_TOKENThere',\n",
       " 'was',\n",
       " 'no',\n",
       " 'violation,',\n",
       " 'you',\n",
       " 'removed',\n",
       " 'factual',\n",
       " 'material.NEWLINE_TOKENNEWLINE_TOKEN:Ditto',\n",
       " 'again',\n",
       " 'the',\n",
       " 'above',\n",
       " 'statement.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'also',\n",
       " 'informed',\n",
       " \"Wikipedia's\",\n",
       " 'administrators',\n",
       " 'of',\n",
       " 'your',\n",
       " 'persistent',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'insert',\n",
       " 'subjective',\n",
       " 'material',\n",
       " 'into',\n",
       " 'this',\n",
       " 'article,',\n",
       " 'in',\n",
       " 'violation',\n",
       " 'of',\n",
       " 'WP:NPOV.',\n",
       " 'NEWLINE_TOKEN=Ditto',\n",
       " 'to',\n",
       " 'that=NEWLINE_TOKENThere',\n",
       " 'was',\n",
       " 'no',\n",
       " 'violation,',\n",
       " 'you',\n",
       " 'removed',\n",
       " 'factual',\n",
       " 'material.NEWLINE_TOKENNEWLINE_TOKEN::Greetings.',\n",
       " 'Uncyclopedia',\n",
       " 'is',\n",
       " 'not',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'Wikimedia,',\n",
       " 'and',\n",
       " 'continuing',\n",
       " 'to',\n",
       " 'insert',\n",
       " 'this',\n",
       " 'false',\n",
       " 'information',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'vandalism.',\n",
       " 'Also,',\n",
       " 'please',\n",
       " 'heed',\n",
       " \"Codeine's\",\n",
       " 'warnings',\n",
       " 'about',\n",
       " 'NPOV;',\n",
       " 'opinions',\n",
       " 'do',\n",
       " 'not',\n",
       " 'belong',\n",
       " 'in',\n",
       " 'Wikipedia',\n",
       " 'articles.',\n",
       " 'Thanks,',\n",
       " 'NEWLINE_TOKEN=Bullshit=NEWLINE_TOKENThere',\n",
       " 'is',\n",
       " 'a',\n",
       " 'connection',\n",
       " 'between',\n",
       " 'Wikia',\n",
       " 'and',\n",
       " 'Wikimedia,',\n",
       " 'Wikia',\n",
       " 'pwns',\n",
       " 'Uncyc.',\n",
       " 'Sorry,',\n",
       " 'loyalist.NEWLINE_TOKENNEWLINE_TOKEN==Your',\n",
       " 'edit',\n",
       " 'to',\n",
       " 'Uncyclopedia==NEWLINE_TOKENYour',\n",
       " 'recent',\n",
       " 'edit',\n",
       " 'to',\n",
       " 'Uncyclopedia',\n",
       " '(diff)',\n",
       " 'was',\n",
       " 'reverted',\n",
       " 'by',\n",
       " 'an',\n",
       " 'automated',\n",
       " 'bot',\n",
       " 'that',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'and',\n",
       " 'repair',\n",
       " 'vandalism',\n",
       " 'to',\n",
       " 'Wikipedia',\n",
       " 'articles.',\n",
       " 'If',\n",
       " 'the',\n",
       " 'bot',\n",
       " 'reverted',\n",
       " 'a',\n",
       " 'legitimate',\n",
       " 'edit,',\n",
       " 'please',\n",
       " 'accept',\n",
       " 'my',\n",
       " 'humble',\n",
       " \"creator's\",\n",
       " 'apologies',\n",
       " '–',\n",
       " 'if',\n",
       " 'you',\n",
       " 'bring',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'attention',\n",
       " 'of',\n",
       " 'the',\n",
       " \"bot's\",\n",
       " 'owner,',\n",
       " 'we',\n",
       " 'may',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'its',\n",
       " 'behavior.',\n",
       " \"'''\",\n",
       " 'for',\n",
       " 'frequently',\n",
       " 'asked',\n",
       " \"questions'''\",\n",
       " 'about',\n",
       " 'the',\n",
       " 'bot',\n",
       " 'and',\n",
       " 'this',\n",
       " 'warning.',\n",
       " '//',\n",
       " 'NEWLINE_TOKEN=',\n",
       " 'Bullshit=NEWLINE_TOKENThere',\n",
       " 'was',\n",
       " 'no',\n",
       " 'violation,',\n",
       " 'you',\n",
       " 'removed',\n",
       " 'factual',\n",
       " 'material.NEWLINE_TOKENNEWLINE_TOKEN:Ditto',\n",
       " 'again',\n",
       " 'the',\n",
       " 'above',\n",
       " 'statement.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'also',\n",
       " 'informed',\n",
       " \"Wikipedia's\",\n",
       " 'administrators',\n",
       " 'of',\n",
       " 'your',\n",
       " 'persistent',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'insert',\n",
       " 'subjective',\n",
       " 'material',\n",
       " 'into',\n",
       " 'this',\n",
       " 'article,',\n",
       " 'in',\n",
       " 'violation',\n",
       " 'of',\n",
       " 'WP:NPOV.',\n",
       " 'NEWLINE_TOKEN=Ditto',\n",
       " 'to',\n",
       " 'that=NEWLINE_TOKENThere',\n",
       " 'was',\n",
       " 'no',\n",
       " 'violation,',\n",
       " 'you',\n",
       " 'removed',\n",
       " 'factual',\n",
       " 'material.NEWLINE_TOKENNEWLINE_TOKEN::Greetings.',\n",
       " 'Uncyclopedia',\n",
       " 'is',\n",
       " 'not',\n",
       " 'associated',\n",
       " 'with',\n",
       " 'Wikimedia,',\n",
       " 'and',\n",
       " 'continuing',\n",
       " 'to',\n",
       " 'insert',\n",
       " 'this',\n",
       " 'false',\n",
       " 'information',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'vandalism.',\n",
       " 'Also,',\n",
       " 'please',\n",
       " 'heed',\n",
       " \"Codeine's\",\n",
       " 'warnings',\n",
       " 'about',\n",
       " 'NPOV;',\n",
       " 'opinions',\n",
       " 'do',\n",
       " 'not',\n",
       " 'belong',\n",
       " 'in',\n",
       " 'Wikipedia',\n",
       " 'articles.',\n",
       " 'Thanks,',\n",
       " 'NEWLINE_TOKEN=Bullshit=NEWLINE_TOKENThere',\n",
       " 'is',\n",
       " 'a',\n",
       " 'connection',\n",
       " 'between',\n",
       " 'Wikia',\n",
       " 'and',\n",
       " 'Wikimedia,',\n",
       " 'Wikia',\n",
       " 'pwns',\n",
       " 'Uncyc.',\n",
       " 'Sorry,',\n",
       " 'loyalist.NEWLINE_TOKENNEWLINE_TOKEN==Your',\n",
       " 'edit',\n",
       " 'to',\n",
       " 'Uncyclopedia==NEWLINE_TOKENYour',\n",
       " 'recent',\n",
       " 'edit',\n",
       " 'to',\n",
       " 'Uncyclopedia',\n",
       " '(diff)',\n",
       " 'was',\n",
       " 'reverted',\n",
       " 'by',\n",
       " 'an',\n",
       " 'automated',\n",
       " 'bot',\n",
       " 'that',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'and',\n",
       " 'repair',\n",
       " 'vandalism',\n",
       " 'to',\n",
       " 'Wikipedia',\n",
       " 'articles.',\n",
       " 'If',\n",
       " 'the',\n",
       " 'bot',\n",
       " 'reverted',\n",
       " 'a',\n",
       " 'legitimate',\n",
       " 'edit,',\n",
       " 'please',\n",
       " 'accept',\n",
       " 'my',\n",
       " 'humble',\n",
       " \"creator's\",\n",
       " 'apologies',\n",
       " '–',\n",
       " 'if',\n",
       " 'you',\n",
       " 'bring',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'attention',\n",
       " 'of',\n",
       " 'the',\n",
       " \"bot's\",\n",
       " 'owner,',\n",
       " 'we',\n",
       " 'may',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'its',\n",
       " 'behavior.',\n",
       " \"'''\",\n",
       " 'for',\n",
       " 'frequently',\n",
       " 'asked',\n",
       " \"questions'''\",\n",
       " 'about',\n",
       " 'the',\n",
       " 'bot',\n",
       " 'and',\n",
       " 'this',\n",
       " 'warning.',\n",
       " '//',\n",
       " 'NEWLINE_TOKEN=',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENGod',\n",
       " 'damn',\n",
       " 'you',\n",
       " 'hectorine,',\n",
       " 'nobody',\n",
       " 'said',\n",
       " 'anything',\n",
       " 'about',\n",
       " 'the',\n",
       " 'article',\n",
       " 'of',\n",
       " 'Angelos',\n",
       " 'elefantis',\n",
       " 'about',\n",
       " 'being',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wrong',\n",
       " 'place,',\n",
       " 'dont',\n",
       " 'make',\n",
       " 'up',\n",
       " 'things..anyway',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'change',\n",
       " 'now',\n",
       " 'the',\n",
       " 'article.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'almost',\n",
       " 'about',\n",
       " 'to',\n",
       " 'think',\n",
       " 'this',\n",
       " 'place',\n",
       " 'is',\n",
       " 'run',\n",
       " 'by',\n",
       " 'greek',\n",
       " 'mafia.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENGod',\n",
       " 'damn',\n",
       " 'you',\n",
       " 'hectorine,',\n",
       " 'nobody',\n",
       " 'said',\n",
       " 'anything',\n",
       " 'about',\n",
       " 'the',\n",
       " 'article',\n",
       " 'of',\n",
       " 'Angelos',\n",
       " 'elefantis',\n",
       " 'about',\n",
       " 'being',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wrong',\n",
       " 'place,',\n",
       " 'dont',\n",
       " 'make',\n",
       " 'up',\n",
       " 'things..anyway',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'change',\n",
       " 'now',\n",
       " 'the',\n",
       " 'article.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'almost',\n",
       " 'about',\n",
       " 'to',\n",
       " 'think',\n",
       " 'this',\n",
       " 'place',\n",
       " 'is',\n",
       " 'run',\n",
       " 'by',\n",
       " 'greek',\n",
       " 'mafia.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENGod',\n",
       " 'damn',\n",
       " 'you',\n",
       " 'hectorine,',\n",
       " 'nobody',\n",
       " 'said',\n",
       " 'anything',\n",
       " 'about',\n",
       " 'the',\n",
       " 'article',\n",
       " 'of',\n",
       " 'Angelos',\n",
       " 'elefantis',\n",
       " 'about',\n",
       " 'being',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wrong',\n",
       " 'place,',\n",
       " 'dont',\n",
       " 'make',\n",
       " 'up',\n",
       " 'things..anyway',\n",
       " 'i',\n",
       " 'cant',\n",
       " 'change',\n",
       " 'now',\n",
       " 'the',\n",
       " 'article.',\n",
       " 'i',\n",
       " 'am',\n",
       " 'almost',\n",
       " 'about',\n",
       " 'to',\n",
       " 'think',\n",
       " 'this',\n",
       " 'place',\n",
       " 'is',\n",
       " 'run',\n",
       " 'by',\n",
       " 'greek',\n",
       " 'mafia.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKENNo',\n",
       " 'defense',\n",
       " 'for',\n",
       " 'firing?',\n",
       " 'This',\n",
       " 'was',\n",
       " 'a',\n",
       " 'man',\n",
       " 'who',\n",
       " 'was',\n",
       " 'found',\n",
       " 'guilty',\n",
       " 'of',\n",
       " 'sexual',\n",
       " 'harassment',\n",
       " 'by',\n",
       " 'a',\n",
       " 'government',\n",
       " 'investigator,',\n",
       " 'and',\n",
       " 'then',\n",
       " 'later',\n",
       " 'convicted',\n",
       " 'in',\n",
       " 'a',\n",
       " 'court',\n",
       " 'of',\n",
       " 'law.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'have',\n",
       " 'information',\n",
       " 'that',\n",
       " 'is',\n",
       " 'not',\n",
       " 'in',\n",
       " 'the',\n",
       " 'public',\n",
       " 'domain,',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'secret',\n",
       " 'legal',\n",
       " 'opinion',\n",
       " 'obtained',\n",
       " 'by',\n",
       " 'Lorne',\n",
       " \"Calvert's\",\n",
       " 'government',\n",
       " 'concerning',\n",
       " 'the',\n",
       " 'firing',\n",
       " 'of',\n",
       " 'Murdoch',\n",
       " 'Carriere,',\n",
       " 'then',\n",
       " 'I',\n",
       " 'would',\n",
       " 'implore',\n",
       " 'you',\n",
       " 'to',\n",
       " 'table',\n",
       " 'that',\n",
       " 'opinion',\n",
       " 'here',\n",
       " '(or',\n",
       " 'on',\n",
       " 'the',\n",
       " 'internet).',\n",
       " 'Otherwise,',\n",
       " 'all',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'concluded',\n",
       " 'is',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'sheer',\n",
       " 'misconduct',\n",
       " 'and',\n",
       " 'bungling',\n",
       " 'on',\n",
       " 'the',\n",
       " 'part',\n",
       " 'of',\n",
       " 'Calvert',\n",
       " 'and',\n",
       " 'his',\n",
       " 'government',\n",
       " 'that',\n",
       " 'led',\n",
       " 'to',\n",
       " 'the',\n",
       " 'payment',\n",
       " 'of',\n",
       " '$275,000',\n",
       " 'plus',\n",
       " 'additional',\n",
       " 'sums',\n",
       " 'relating',\n",
       " 'to',\n",
       " 'pension',\n",
       " 'credits.NEWLINE_TOKENNEWLINE_TOKENTable',\n",
       " 'the',\n",
       " 'legal',\n",
       " 'opinion',\n",
       " 'if',\n",
       " 'you',\n",
       " 'have',\n",
       " 'it,',\n",
       " 'or',\n",
       " 'tell',\n",
       " 'your',\n",
       " 'cronies',\n",
       " 'in',\n",
       " 'the',\n",
       " 'party',\n",
       " 'to',\n",
       " 'convince',\n",
       " 'Calvert',\n",
       " 'to',\n",
       " 'table',\n",
       " 'the',\n",
       " 'opinion',\n",
       " 'under',\n",
       " 'the',\n",
       " 'immunity',\n",
       " 'of',\n",
       " 'Parliamentary',\n",
       " 'Priviledge.',\n",
       " 'Otherwise,',\n",
       " 'your',\n",
       " 'beloved',\n",
       " 'leader',\n",
       " 'and',\n",
       " 'party',\n",
       " 'will',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'fall',\n",
       " 'victim',\n",
       " 'to',\n",
       " 'the',\n",
       " 'criticisms',\n",
       " 'that',\n",
       " 'have',\n",
       " 'been',\n",
       " 'levelled',\n",
       " 'against',\n",
       " 'it,',\n",
       " 'and',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'credibly',\n",
       " 'defend',\n",
       " 'itself.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN',\n",
       " 'Dude.',\n",
       " 'Vandalism',\n",
       " 'sucks.',\n",
       " 'You',\n",
       " 'are',\n",
       " 'so',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'banned.',\n",
       " 'NEWLINE_TOKENNEWLINE_TOKEN==',\n",
       " 'what',\n",
       " 'the',\n",
       " 'hell!!!!',\n",
       " '==NEWLINE_TOKENNEWLINE_TOKENwhat',\n",
       " 'the',\n",
       " 'hell',\n",
       " 'is',\n",
       " 'your',\n",
       " 'fucking',\n",
       " 'problem?',\n",
       " 'i',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'sue',\n",
       " 'the',\n",
       " 'fucking',\n",
       " 'pants',\n",
       " 'off',\n",
       " 'of',\n",
       " 'you',\n",
       " 'for',\n",
       " 'dicrimination',\n",
       " 'against',\n",
       " 'a',\n",
       " 'minority',\n",
       " 'you',\n",
       " 'mother',\n",
       " 'fucking',\n",
       " 'asshole!!!!',\n",
       " 'i',\n",
       " 'will',\n",
       " 'kill',\n",
       " 'you',\n",
       " 'the',\n",
       " 'next',\n",
       " 'time',\n",
       " 'you',\n",
       " 'try',\n",
       " 'anything.',\n",
       " 'go',\n",
       " 'ahead',\n",
       " 'block',\n",
       " 'my',\n",
       " 'account,',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'give',\n",
       " 'a',\n",
       " 'shit!!!!',\n",
       " 'you',\n",
       " ...]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fem_tox_words = []\n",
    "fem_tox = tox.loc[tox['gender'] == 'female']\n",
    "fem_tox.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for i in range(len(fem_tox)):\n",
    "    fem_tox_words.extend(fem_tox['comment'][i].split())\n",
    "    \n",
    "fem_tox_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
